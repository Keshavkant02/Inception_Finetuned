# Pneumonia Detection from Chest X-Rays using Transfer Learning

**A deep learning project to fine-tune an Inception-V3 model on the PneumoniaMNIST dataset for classifying chest X-rays as showing signs of pneumonia or being normal.**

---

## Table of Contents
1.  [Project Objective](#project-objective)
2.  [Key Features](#key-features)
3.  [Dataset](#dataset)
4.  [Methodology](#methodology)
5.  [Results and Analysis](#results-and-analysis)
6.  [Setup and Installation](#setup-and-installation)
7.  [How to Run the Script](#how-to-run-the-script)
8.  [File Structure](#file-structure)
9.  [Technologies Used](#technologies-used)

---

## Project Objective

The primary objective of this project is to develop and evaluate a deep learning model for medical image classification. This involves:
-   **Fine-tuning a pre-trained Inception-V3 architecture** to distinguish between "Pneumonia" and "Normal" chest X-ray images.
-   Implementing a robust **evaluation strategy** using appropriate metrics for an imbalanced medical dataset.
-   Applying techniques to **mitigate class imbalance** and **prevent overfitting**.
-   Reporting on the model's final performance and providing insights into its clinical applicability.

---

## Key Features

-   **Transfer Learning:** Leverages the powerful, pre-trained Inception-V3 model from `torchvision` to achieve high performance with a relatively small dataset.
-   **Class Imbalance Mitigation:** Employs a weighted loss function (`nn.CrossEntropyLoss` with class weights) to force the model to pay equal attention to the minority "Normal" class during training.
-   **Overfitting Prevention:** Utilizes a combination of **Data Augmentation** (random rotations, flips, and color jitter) and **Regularization** (Dropout layers and Weight Decay) to ensure the model generalizes well to unseen data.
-   **Comprehensive Evaluation:** Goes beyond simple accuracy to report on **AUC-ROC, Precision, and Recall**, providing a clear picture of the model's clinical trade-offs.
-   **Reproducible "Sleep-Friendly" Script:** The main script is designed for unattended training sessions, with features like automatic checkpointing of the best model and detailed progress logging.

---

## Dataset
*(Describe the data you used. This provides essential context.)*

This project utilizes the **PneumoniaMNIST** dataset, which is part of the MedMNIST v2 collection.

-   **Source:** [MedMNIST Homepage](https://medmnist.com/)
-   **Description:** The dataset consists of 5,856 chest X-ray images, down-sampled to 28x28 pixels and standardized. The images are categorized into two classes:
    1.  **Normal**
    2.  **Pneumonia**
-   **Class Imbalance:** The training set exhibits a significant class imbalance, with **3,875 "Pneumonia" samples** and only **1,341 "Normal" samples**. This imbalance was a key challenge addressed in the project.

---

## Methodology

The project follows a standard transfer learning pipeline:

1.  **Data Preprocessing & Augmentation:** Input images are resized to the required `299x299` for Inception-V3. The training data undergoes on-the-fly augmentation to prevent overfitting. All images are converted to 3-channel tensors and normalized using ImageNet statistics.

2.  **Model Architecture:** A pre-trained Inception-V3 model is loaded. All of its base layers are **frozen** to preserve the learned ImageNet features. The final fully connected layer (`fc`) is **replaced** with a new custom classifier head containing a Dropout layer for regularization. Only this new head is trained.

3.  **Training Strategy:**
    -   **Loss Function:** A weighted `CrossEntropyLoss` is used to counteract the dataset's class imbalance.
    -   **Optimizer:** The Adam optimizer is used with weight decay (L2 regularization).
    -   **Learning Rate Scheduler:** A `ReduceLROnPlateau` scheduler dynamically lowers the learning rate if the validation loss stops improving, helping the model find a better minimum.

---

## Results and Analysis

The model was trained for 10 epochs, and the best-performing version (based on validation loss) was evaluated on the held-out test set.

### Quantitative Results

The final performance on the test set is summarized below:

| Metric          | Score           |
|-----------------|-----------------|
| **ROC AUC**     | **0.8889**      |
| Accuracy        | 0.7997          |
|                 |                 |
| **Normal Class**|                 |
| Precision       | 0.86            |
| Recall          | 0.56            |
| F1-Score        | 0.68            |
|                 |                 |
| **Pneumonia Class**|                |
| Precision       | 0.78            |
| **Recall**      | **0.94**        |
| F1-Score        | 0.85            |


### Visual Results

*(You should include the plots generated by your script here. Take screenshots and add them to your repository.)*

![Training and Validation Loss Curves](path/to/your/loss_plot.png)
*Figure 1: Training and validation loss curves show good convergence without significant overfitting.*

![Confusion Matrix](path/to/your/confusion_matrix.png)
*Figure 2: The confusion matrix for the test set, showing the distribution of true vs. predicted labels.*

### Analysis & Insights

-   The high **ROC AUC score of 0.89** indicates that the model has excellent discriminative ability, successfully learning to separate the two classes.
-   The key finding is the trade-off in recall. The model achieved an outstanding **Recall of 0.94 for the Pneumonia class**, meaning it successfully identified 94% of all sick patients. This is a highly desirable outcome for a diagnostic screening tool, as it minimizes dangerous false negatives.
-   This high sensitivity, however, came at the cost of a **lower Recall (0.56) for the Normal class**. This means the model has a tendency to be overcautious, flagging a significant number of healthy patients for follow-up (false positives). This is a classic precision-recall trade-off, and for a life-threatening illness, a bias towards higher recall is often preferred.

---

## Setup and Installation

To set up the environment and run this project, please follow these steps:

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/your-username/your-repo-name.git
    cd your-repo-name
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    ```

3.  **Install the required dependencies:**
    The `requirements.txt` file contains all necessary Python packages.
    ```bash
    pip install -r requirements.txt
    ```

---

## How to Run the Script

Once the setup is complete, you can run the entire training and evaluation pipeline with a single command:

```bash
python your_script_name.py
```

The script will:
-   Download the dataset.
-   Build the model.
-   Run the training and validation loop for 10 epochs.
-   Save the best model weights to `best_model.pth`.
-   Save a detailed log to `training_log_...txt`.
-   Print the final evaluation metrics and display the result plots.

---

## File Structure

```
.
├── your_script_name.py     # Main Python script for training and evaluation
├── requirements.txt        # List of all Python dependencies
├── README.md               # This documentation file
├── best_model.pth          # (Output) Saved weights of the best performing model
├── training_log_...txt     # (Output) Detailed log file from the training run
└── plots/                    # (Output) Directory for saved result images
    ├── loss_plot.png
    └── confusion_matrix.png
```

---

## Technologies Used

-   **Python 3.x**
-   **PyTorch:** The primary deep learning framework.
-   **MedMNIST:** For easy and standardized dataset access.
-   **scikit-learn:** For calculating evaluation metrics and class weights.
-   **NumPy:** For numerical operations.
-   **Matplotlib & Seaborn:** For data visualization and plotting results.
-   **Jupyter / Google Colab:** As the development environment.
